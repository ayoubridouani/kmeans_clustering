{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pfisher/.local/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mahotas\n",
    "import cv2\n",
    "import glob\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv_file(y_pred, imgs_to_predict):\n",
    "    csv_filename = '2C_prediction.csv'\n",
    "    with open(csv_filename, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['image_id', 'classe']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for i in range(len(y_pred)):\n",
    "            filename = imgs_to_predict[i]\n",
    "            classname = y_pred[i]\n",
    "            writer.writerow({'image_id' : filename, 'classe' : classname})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descripteur 0: Color Moments\n",
    "def color_moments(image):\n",
    "    R = image[:,:,0]\n",
    "    G = image[:,:,1]\n",
    "    B = image[:,:,2]\n",
    "    colorFeature=[\n",
    "            np.mean(R), np.std(R),\n",
    "            np.mean(G), np.std(G),\n",
    "            np.mean(B), np.std(B)\n",
    "    ]\n",
    "    colorFeature = colorFeature/np.mean(colorFeature)\n",
    "    return colorFeature.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descripteur 1: Forme\n",
    "def forme(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # extraction de la forme\n",
    "    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n",
    "    return feature.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descripteur 2: Texture\n",
    "def texture(image):\n",
    "    # convertir l'image en niveaux de gris\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # extraction de la texture \n",
    "    haralick = mahotas.features.haralick(gray).mean(axis=0)\n",
    "    return haralick.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descripteur 3: Histogramme\n",
    "def histogramme(image, mask=None):\n",
    "    # convert l'image en espace de couleur HSV \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    # extraction d'histogramme\n",
    "    hist  = cv2.calcHist([image], [0, 1, 2], mask, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    # normalisation d'histogramme\n",
    "    cv2.normalize(hist, hist)\n",
    "    return hist.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of features extractions...\n"
     ]
    }
   ],
   "source": [
    "# tailles fixes pour l'image\n",
    "fixed_size = tuple((120, 80))\n",
    "\n",
    "# chemin pour les données d'entraînement\n",
    "train_path = \"2Classes\"\n",
    "\n",
    "# listes vides pour les vecteurs et les étiquettes\n",
    "global_features = []\n",
    "\n",
    "# boucle sur les images dans chaque sous-dossier\n",
    "path = glob.glob(\"2Classes\"+\"/*.jpg\")\n",
    "image_names = []\n",
    "for file in path:\n",
    "    image = cv2.imread(file)\n",
    "    #image = cv2.resize(image, fixed_size,interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    # extraction des Features\n",
    "    image_names.append(file.split('/')[-1])\n",
    "    forme_ = forme(image)\n",
    "    texture_   = texture(image)\n",
    "    colormoments_ = color_moments(image)\n",
    "    histogramme_  = histogramme(image)\n",
    "        \n",
    "    # Concatener les features\n",
    "    global_feature=histogramme_\n",
    "    global_feature.extend(texture_)\n",
    "    global_feature.extend(colormoments_)\n",
    "    global_feature.extend(forme_)\n",
    "    \n",
    "    global_features.append(global_feature)\n",
    "    \n",
    "print(\"End of features extractions...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(global_features)\n",
    "sklearn_pca = PCA(n_components =13)\n",
    "Y_sklearn = sklearn_pca.fit_transform(np.array(X).astype('float'))\n",
    "\n",
    "kmeans = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')\n",
    "\n",
    "result=kmeans.fit_predict(Y_sklearn)\n",
    "result=result+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sauvegarder le resultat\n",
    "create_csv_file(result,image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauvegarder le model\n",
    "filename = 'model2Classes.sav'\n",
    "joblib.dump(kmeans, filename)\n",
    "     \n",
    "# some time later...\n",
    "# load the model from disk\n",
    "Y_test=[]\n",
    "for i in range(0,200):\n",
    "    if i<100 : Y_test.append(0)\n",
    "    else : Y_test.append(1)\n",
    "\n",
    "loaded_model = joblib.load('model2Classes.sav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
